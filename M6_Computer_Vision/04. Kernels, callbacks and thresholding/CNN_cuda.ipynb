{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\r\n",
    "%config InlineBackend.figure_format = 'retina'\r\n",
    "\r\n",
    "from collections import OrderedDict\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import time\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch import optim\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "def view_classify(img, ps):\r\n",
    "\r\n",
    "    ps = ps.data.numpy().squeeze()\r\n",
    "\r\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\r\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\r\n",
    "    ax1.axis('off')\r\n",
    "    ax2.barh(np.arange(10), ps)\r\n",
    "    ax2.set_aspect(0.1)\r\n",
    "    ax2.set_yticks(np.arange(10))\r\n",
    "    ax2.set_yticklabels(np.arange(10))\r\n",
    "    ax2.set_title('Class Probability')\r\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\r\n",
    "\r\n",
    "# Download and load the training data\r\n",
    "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\r\n",
    "\r\n",
    "# Download and load the test data\r\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\r\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\r\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Net,self).__init__()\r\n",
    "\r\n",
    "        self.layer1 = nn.Sequential(\r\n",
    "            nn.Conv2d(1,16,5),\r\n",
    "            nn.BatchNorm2d(16),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.MaxPool2d(2))\r\n",
    "        self.layer2 = nn.Sequential(\r\n",
    "            nn.Conv2d(16,32,5),\r\n",
    "            #nn.BatchNorm2d(32),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.MaxPool2d(2))\r\n",
    "        #self.layer3 = nn.Sequential(\r\n",
    "        #    nn.Conv2d(32,64,5),\r\n",
    "        #    #nn.BatchNorm2d(),\r\n",
    "        #    nn.ReLU(inplace=True),\r\n",
    "        #    nn.MaxPool2d(2)\r\n",
    "        #            )\r\n",
    "        self.fc = nn.Sequential(\r\n",
    "            nn.Linear(32 *4 *4,128),\r\n",
    "            nn.ReLU(inplace =True),\r\n",
    "            nn.Linear(128,64),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Linear(64,32),\r\n",
    "            nn.Linear(32,10))\r\n",
    "    \r\n",
    "    def forward(self,x):\r\n",
    "        x = self.layer1(x)\r\n",
    "        x = self.layer2(x)\r\n",
    "        #x = self.layer3(x)\r\n",
    "        x = x.view(x.size(0), -1)\r\n",
    "        x = self.fc(x)\r\n",
    "        #x = F.softmax(x, dim=1)\r\n",
    "\r\n",
    "        return x\r\n",
    "\r\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\r\n",
    "y = images.resize_(images.shape[0], 1, 28,28)\r\n",
    "ps = model.forward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\r\n",
    "if torch.cuda.is_available():\r\n",
    "    model = model.cuda()\r\n",
    "    criterion = criterion.cuda()\r\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "\tIteration: 0\t Loss: 0.0006\n",
      "\tIteration: 50\t Loss: 0.1228\n",
      "\tIteration: 100\t Loss: 0.1343\n",
      "\tIteration: 150\t Loss: 0.1270\n",
      "\tIteration: 200\t Loss: 0.1288\n",
      "\tIteration: 250\t Loss: 0.1210\n",
      "\tIteration: 300\t Loss: 0.1048\n",
      "\tIteration: 350\t Loss: 0.1318\n",
      "\tIteration: 400\t Loss: 0.1233\n",
      "\tIteration: 450\t Loss: 0.1231\n",
      "\tIteration: 500\t Loss: 0.1151\n",
      "\tIteration: 550\t Loss: 0.0946\n",
      "\tIteration: 600\t Loss: 0.1000\n",
      "\tIteration: 650\t Loss: 0.1175\n",
      "\tIteration: 700\t Loss: 0.1293\n",
      "\tIteration: 750\t Loss: 0.0936\n",
      "\tIteration: 800\t Loss: 0.1074\n",
      "\tIteration: 850\t Loss: 0.0975\n",
      "\tIteration: 900\t Loss: 0.0958\n",
      "\tIteration: 950\t Loss: 0.1117\n",
      "\tIteration: 1000\t Loss: 0.1175\n",
      "\tIteration: 1050\t Loss: 0.0968\n",
      "\tIteration: 1100\t Loss: 0.1055\n",
      "\tIteration: 1150\t Loss: 0.0994\n",
      "\tIteration: 1200\t Loss: 0.1064\n",
      "\tIteration: 1250\t Loss: 0.0766\n",
      "\tIteration: 1300\t Loss: 0.0940\n",
      "\tIteration: 1350\t Loss: 0.1116\n",
      "\tIteration: 1400\t Loss: 0.1189\n",
      "\tIteration: 1450\t Loss: 0.0769\n",
      "\tIteration: 1500\t Loss: 0.0977\n",
      "\tIteration: 1550\t Loss: 0.0975\n",
      "\tIteration: 1600\t Loss: 0.0767\n",
      "\tIteration: 1650\t Loss: 0.0920\n",
      "\tIteration: 1700\t Loss: 0.1159\n",
      "\tIteration: 1750\t Loss: 0.0896\n",
      "\tIteration: 1800\t Loss: 0.1033\n",
      "\tIteration: 1850\t Loss: 0.0757\n",
      "Accuracy of the network: 97 %\n",
      "Epoch: 2/5\n",
      "\tIteration: 0\t Loss: 0.0011\n",
      "\tIteration: 50\t Loss: 0.0590\n",
      "\tIteration: 100\t Loss: 0.0846\n",
      "\tIteration: 150\t Loss: 0.0761\n",
      "\tIteration: 200\t Loss: 0.0620\n",
      "\tIteration: 250\t Loss: 0.1012\n",
      "\tIteration: 300\t Loss: 0.0780\n",
      "\tIteration: 350\t Loss: 0.0761\n",
      "\tIteration: 400\t Loss: 0.0826\n",
      "\tIteration: 450\t Loss: 0.0725\n",
      "\tIteration: 500\t Loss: 0.0765\n",
      "\tIteration: 550\t Loss: 0.0745\n",
      "\tIteration: 600\t Loss: 0.0928\n",
      "\tIteration: 650\t Loss: 0.0794\n",
      "\tIteration: 700\t Loss: 0.0704\n",
      "\tIteration: 750\t Loss: 0.0704\n",
      "\tIteration: 800\t Loss: 0.0759\n",
      "\tIteration: 850\t Loss: 0.0621\n",
      "\tIteration: 900\t Loss: 0.0859\n",
      "\tIteration: 950\t Loss: 0.0906\n",
      "\tIteration: 1000\t Loss: 0.0837\n",
      "\tIteration: 1050\t Loss: 0.0650\n",
      "\tIteration: 1100\t Loss: 0.0862\n",
      "\tIteration: 1150\t Loss: 0.0876\n",
      "\tIteration: 1200\t Loss: 0.0836\n",
      "\tIteration: 1250\t Loss: 0.0555\n",
      "\tIteration: 1300\t Loss: 0.0608\n",
      "\tIteration: 1350\t Loss: 0.0566\n",
      "\tIteration: 1400\t Loss: 0.0757\n",
      "\tIteration: 1450\t Loss: 0.0586\n",
      "\tIteration: 1500\t Loss: 0.0719\n",
      "\tIteration: 1550\t Loss: 0.0764\n",
      "\tIteration: 1600\t Loss: 0.0564\n",
      "\tIteration: 1650\t Loss: 0.0882\n",
      "\tIteration: 1700\t Loss: 0.0602\n",
      "\tIteration: 1750\t Loss: 0.0719\n",
      "\tIteration: 1800\t Loss: 0.0527\n",
      "\tIteration: 1850\t Loss: 0.0709\n",
      "Accuracy of the network: 98 %\n",
      "Epoch: 3/5\n",
      "\tIteration: 0\t Loss: 0.0006\n",
      "\tIteration: 50\t Loss: 0.0620\n",
      "\tIteration: 100\t Loss: 0.0600\n",
      "\tIteration: 150\t Loss: 0.0467\n",
      "\tIteration: 200\t Loss: 0.0658\n",
      "\tIteration: 250\t Loss: 0.0394\n",
      "\tIteration: 300\t Loss: 0.0492\n",
      "\tIteration: 350\t Loss: 0.0586\n",
      "\tIteration: 400\t Loss: 0.0825\n",
      "\tIteration: 450\t Loss: 0.0627\n",
      "\tIteration: 500\t Loss: 0.0528\n",
      "\tIteration: 550\t Loss: 0.0713\n",
      "\tIteration: 600\t Loss: 0.0467\n",
      "\tIteration: 650\t Loss: 0.0600\n",
      "\tIteration: 700\t Loss: 0.0505\n",
      "\tIteration: 750\t Loss: 0.0651\n",
      "\tIteration: 800\t Loss: 0.0679\n",
      "\tIteration: 850\t Loss: 0.0740\n",
      "\tIteration: 900\t Loss: 0.0801\n",
      "\tIteration: 950\t Loss: 0.0502\n",
      "\tIteration: 1000\t Loss: 0.0568\n",
      "\tIteration: 1050\t Loss: 0.0557\n",
      "\tIteration: 1100\t Loss: 0.0520\n",
      "\tIteration: 1150\t Loss: 0.0494\n",
      "\tIteration: 1200\t Loss: 0.0579\n",
      "\tIteration: 1250\t Loss: 0.0682\n",
      "\tIteration: 1300\t Loss: 0.0578\n",
      "\tIteration: 1350\t Loss: 0.0652\n",
      "\tIteration: 1400\t Loss: 0.0444\n",
      "\tIteration: 1450\t Loss: 0.0478\n",
      "\tIteration: 1500\t Loss: 0.0478\n",
      "\tIteration: 1550\t Loss: 0.0638\n",
      "\tIteration: 1600\t Loss: 0.0413\n",
      "\tIteration: 1650\t Loss: 0.0447\n",
      "\tIteration: 1700\t Loss: 0.0381\n",
      "\tIteration: 1750\t Loss: 0.0602\n",
      "\tIteration: 1800\t Loss: 0.0611\n",
      "\tIteration: 1850\t Loss: 0.0734\n",
      "Accuracy of the network: 98 %\n",
      "Epoch: 4/5\n",
      "\tIteration: 0\t Loss: 0.0042\n",
      "\tIteration: 50\t Loss: 0.0473\n",
      "\tIteration: 100\t Loss: 0.0414\n",
      "\tIteration: 150\t Loss: 0.0457\n",
      "\tIteration: 200\t Loss: 0.0577\n",
      "\tIteration: 250\t Loss: 0.0319\n",
      "\tIteration: 300\t Loss: 0.0472\n",
      "\tIteration: 350\t Loss: 0.0585\n",
      "\tIteration: 400\t Loss: 0.0447\n",
      "\tIteration: 450\t Loss: 0.0556\n",
      "\tIteration: 500\t Loss: 0.0466\n",
      "\tIteration: 550\t Loss: 0.0477\n",
      "\tIteration: 600\t Loss: 0.0386\n",
      "\tIteration: 650\t Loss: 0.0390\n",
      "\tIteration: 700\t Loss: 0.0503\n",
      "\tIteration: 750\t Loss: 0.0536\n",
      "\tIteration: 800\t Loss: 0.0428\n",
      "\tIteration: 850\t Loss: 0.0422\n",
      "\tIteration: 900\t Loss: 0.0461\n",
      "\tIteration: 950\t Loss: 0.0540\n",
      "\tIteration: 1000\t Loss: 0.0543\n",
      "\tIteration: 1050\t Loss: 0.0447\n",
      "\tIteration: 1100\t Loss: 0.0460\n",
      "\tIteration: 1150\t Loss: 0.0671\n",
      "\tIteration: 1200\t Loss: 0.0293\n",
      "\tIteration: 1250\t Loss: 0.0467\n",
      "\tIteration: 1300\t Loss: 0.0469\n",
      "\tIteration: 1350\t Loss: 0.0252\n",
      "\tIteration: 1400\t Loss: 0.0411\n",
      "\tIteration: 1450\t Loss: 0.0457\n",
      "\tIteration: 1500\t Loss: 0.0475\n",
      "\tIteration: 1550\t Loss: 0.0279\n",
      "\tIteration: 1600\t Loss: 0.0717\n",
      "\tIteration: 1650\t Loss: 0.0520\n",
      "\tIteration: 1700\t Loss: 0.0499\n",
      "\tIteration: 1750\t Loss: 0.0394\n",
      "\tIteration: 1800\t Loss: 0.0506\n",
      "\tIteration: 1850\t Loss: 0.0584\n",
      "Accuracy of the network: 98 %\n",
      "Epoch: 5/5\n",
      "\tIteration: 0\t Loss: 0.0001\n",
      "\tIteration: 50\t Loss: 0.0440\n",
      "\tIteration: 100\t Loss: 0.0383\n",
      "\tIteration: 150\t Loss: 0.0289\n",
      "\tIteration: 200\t Loss: 0.0492\n",
      "\tIteration: 250\t Loss: 0.0503\n",
      "\tIteration: 300\t Loss: 0.0425\n",
      "\tIteration: 350\t Loss: 0.0313\n",
      "\tIteration: 400\t Loss: 0.0387\n",
      "\tIteration: 450\t Loss: 0.0287\n",
      "\tIteration: 500\t Loss: 0.0307\n",
      "\tIteration: 550\t Loss: 0.0387\n",
      "\tIteration: 600\t Loss: 0.0404\n",
      "\tIteration: 650\t Loss: 0.0327\n",
      "\tIteration: 700\t Loss: 0.0373\n",
      "\tIteration: 750\t Loss: 0.0564\n",
      "\tIteration: 800\t Loss: 0.0384\n",
      "\tIteration: 850\t Loss: 0.0377\n",
      "\tIteration: 900\t Loss: 0.0267\n",
      "\tIteration: 950\t Loss: 0.0364\n",
      "\tIteration: 1000\t Loss: 0.0414\n",
      "\tIteration: 1050\t Loss: 0.0454\n",
      "\tIteration: 1100\t Loss: 0.0527\n",
      "\tIteration: 1150\t Loss: 0.0293\n",
      "\tIteration: 1200\t Loss: 0.0508\n",
      "\tIteration: 1250\t Loss: 0.0435\n",
      "\tIteration: 1300\t Loss: 0.0412\n",
      "\tIteration: 1350\t Loss: 0.0452\n",
      "\tIteration: 1400\t Loss: 0.0495\n",
      "\tIteration: 1450\t Loss: 0.0474\n",
      "\tIteration: 1500\t Loss: 0.0326\n",
      "\tIteration: 1550\t Loss: 0.0505\n",
      "\tIteration: 1600\t Loss: 0.0260\n",
      "\tIteration: 1650\t Loss: 0.0437\n",
      "\tIteration: 1700\t Loss: 0.0345\n",
      "\tIteration: 1750\t Loss: 0.0278\n",
      "\tIteration: 1800\t Loss: 0.0274\n",
      "\tIteration: 1850\t Loss: 0.0390\n",
      "Accuracy of the network: 98 %\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\r\n",
    "val_loss = []\r\n",
    "\r\n",
    "epochs = 5\r\n",
    "print_every = 50\r\n",
    "\r\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.1)\r\n",
    "for e in range(epochs):\r\n",
    "    running_loss = 0\r\n",
    "    total = 0\r\n",
    "    correct = 0\r\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\r\n",
    "\r\n",
    "    model.train()\r\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\r\n",
    "\r\n",
    "       \r\n",
    "        images.resize_(images.size()[0], 1,28,28).cuda()\r\n",
    "        \r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        output = model.forward(images.cuda())   # 1) Forward pass\r\n",
    "        loss = criterion(output.cuda(), labels.cuda()) # 2) Compute loss\r\n",
    "        loss.backward()                  # 3) Backward pass\r\n",
    "        optimizer.step()                 # 4) Update model\r\n",
    "        \r\n",
    "        running_loss += loss.item()\r\n",
    "\r\n",
    "        train_loss.append(loss)\r\n",
    "    \r\n",
    "        \r\n",
    "        if i % print_every == 0:\r\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\r\n",
    "            running_loss = 0\r\n",
    "        \r\n",
    "\r\n",
    "    model.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        for i, (images, labels) in enumerate(iter(testloader)):\r\n",
    "            images.resize_(images.size()[0], 1,28,28)\r\n",
    "            outputs = model(images.cuda())\r\n",
    "            _, predicted = torch.max(outputs.data, 1)\r\n",
    "            total += labels.size(0)\r\n",
    "            correct += (predicted == labels.cuda()).sum().item()\r\n",
    "            #loss_val = criterion(output_val, y_val)\r\n",
    "            #val_loss.append(loss_val)\r\n",
    "    print('Accuracy of the network: %d %%' % (\r\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7da0dff66cc1656971d6da80a6d455a6736937c6f28b91b322b223214c78ae6d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('minicyborg': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}