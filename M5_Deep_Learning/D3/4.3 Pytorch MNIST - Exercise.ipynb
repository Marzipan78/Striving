{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\">Deep Learning Fundamentals</h2>\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">Multiclass Classification: MNIST</h2>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:36.081105Z",
     "start_time": "2021-05-26T22:26:35.040138Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxliary plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:37.473177Z",
     "start_time": "2021-05-26T22:26:37.465910Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/view-classify-in-module-helper/30279/6\n",
    "\n",
    "\n",
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Dataset\n",
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:38.402766Z",
     "start_time": "2021-05-26T22:26:38.298968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data (Preprocessing)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:38.632988Z",
     "start_time": "2021-05-26T22:26:38.477558Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. We'd use this to loop through the dataset for training, but here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:39.407000Z",
     "start_time": "2021-05-26T22:26:39.265256Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 251,
       "height": 248
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "Here I'll use PyTorch to build a simple feedfoward network to classify the MNIST images. That is, the network will receive a digit image as input and predict the digit in the image.\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "To build a neural network with PyTorch, you use the `torch.nn` module. The network itself is a class inheriting from `torch.nn.Module`. You define each of the operations separately, like `nn.Linear(784, 128)` for a fully connected linear layer with 784 inputs and 128 units.\n",
    "\n",
    "The class needs to include a `forward` method that implements the forward pass through the network. In this method, you pass some input tensor `x` through each of the operations you defined earlier. The `torch.nn` module also has functional equivalents for things like ReLUs in `torch.nn.functional`. This module is usually imported as `F`. Then to use a ReLU activation on some layer (which is just a tensor), you'd do `F.relu(x)`. Below are a few different commonly used activation functions.\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "So, for this network, I'll build it with three fully connected layers, then a softmax output for predicting classes. The softmax function is similar to the sigmoid in that it squashes inputs between 0 and 1, but it's also normalized so that all the values sum to one like a proper probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:39.961531Z",
     "start_time": "2021-05-26T22:26:39.946776Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    # Defining the layers, 128, 64, 10 units each\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 10)\n",
    "        \n",
    "    # Forward pass through the network, returns the output logits\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the input features are 784? Because the input images have size 28 pixels x 28 pixels for a total of 784 features. Since a Multilayer perceptron accepts only flatten inputs, we need to flatten a 28x28 grid into a 784 array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential API\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:41.213448Z",
     "start_time": "2021-05-26T22:26:41.205216Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n  (0): Linear(in_features=784, out_features=4, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=4, out_features=4, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=4, out_features=10, bias=True)\n  (5): Softmax(dim=1)\n)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = 784\n",
    "hidden_sizes = [4, 4]\n",
    "output_size   = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in an `OrderedDict` to name the individual layers and operations. Note that a dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:42.300216Z",
     "start_time": "2021-05-26T22:26:42.289009Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=4, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=4, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "          ('fc1',   nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2',   nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "          ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:42.972699Z",
     "start_time": "2021-05-26T22:26:42.963913Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[-0.0196,  0.0314,  0.0313,  ...,  0.0195,  0.0055,  0.0100],\n        [ 0.0290,  0.0053, -0.0154,  ..., -0.0238, -0.0334, -0.0280],\n        [-0.0118, -0.0300,  0.0257,  ..., -0.0118,  0.0101,  0.0054],\n        [ 0.0212, -0.0274,  0.0055,  ..., -0.0138,  0.0018,  0.0002]],\n       requires_grad=True)\nParameter containing:\ntensor([-0.0031,  0.0280,  0.0168,  0.0083], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:43.889729Z",
     "start_time": "2021-05-26T22:26:43.883940Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:44.084097Z",
     "start_time": "2021-05-26T22:26:44.076738Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0123,  0.0011,  0.0056,  ...,  0.0162,  0.0008, -0.0043],\n",
       "        [ 0.0140,  0.0017,  0.0072,  ..., -0.0013,  0.0148,  0.0017],\n",
       "        [-0.0045, -0.0057, -0.0159,  ...,  0.0052,  0.0036, -0.0146],\n",
       "        [-0.0113, -0.0120, -0.0039,  ...,  0.0095,  0.0045, -0.0206]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image. This is called the forward pass. We're going to convert the image data into a tensor, then pass it through the operations defined by the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:44.506324Z",
     "start_time": "2021-05-26T22:26:44.491847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:44.596541Z",
     "start_time": "2021-05-26T22:26:44.594169Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:44.851894Z",
     "start_time": "2021-05-26T22:26:44.845888Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=4, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=4, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:46.121246Z",
     "start_time": "2021-05-26T22:26:46.112022Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to not automatically get batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:46.519895Z",
     "start_time": "2021-05-26T22:26:46.514137Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "img_idx = 0\n",
    "images[img_idx,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:47.945952Z",
     "start_time": "2021-05-26T22:26:47.888846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model(images[img_idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:50.561845Z",
     "start_time": "2021-05-26T22:26:50.411449Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x648 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "img = images[img_idx]\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks\n",
    "\n",
    "The network we built isn't so smart, it doesn't know anything about our handwritten digits. Neural networks with non-linear activations work like universal function approximators. There is some function that maps your input to the output. For example, images of handwritten digits to class probabilities. The power of neural networks is that we can train them to approximate this function, and basically any function given enough data and compute time.\n",
    "\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "At first the network is naive, it doesn't know the function mapping the inputs to the outputs. We train the network by showing it examples of real data, then adjusting the network parameters such that it approximates this function.\n",
    "\n",
    "To find these parameters, we need to know how poorly the network is predicting the real outputs. For this we calculate a **loss function** (also called the cost), a measure of our prediction error. For example, the mean squared loss is often used in regression and binary classification problems\n",
    "\n",
    "$$\n",
    "\\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "\n",
    "where $n$ is the number of training examples, $y_i$ are the true labels, and $\\hat{y}_i$ are the predicted labels.\n",
    "\n",
    "By minimizing this loss with respect to the network parameters, we can find configurations where the loss is at a minimum and the network is able to predict the correct labels with high accuracy. We find this minimum using a process called **gradient descent**. The gradient is the slope of the loss function and points in the direction of fastest change. To get to the minimum in the least amount of time, we then want to follow the gradient (downwards). You can think of this like descending a mountain by following the steepest slope to the base.\n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "For single layer networks, gradient descent is simple to implement. However, it's more complicated for deeper, multilayer neural networks like the one we've built. Complicated enough that it took about 30 years before researchers figured out how to train multilayer networks, although it's straightforward once you learn about it. \n",
    "\n",
    "This is done through **backpropagation** which is really just an application of the chain rule from calculus. It's easiest to understand if we convert a two layer network into a graph representation.\n",
    "\n",
    "<img src='assets/w1_backprop_graph.png' width=400px>\n",
    "\n",
    "In the forward pass through the network, our data and operations go from right to left here. To train the weights with gradient descent, we propagate the gradient of the cost backwards through the network. Mathematically, this is really just calculating the gradient of the loss with respect to the weights using the chain rule.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial w_1} = \\frac{\\partial l_1}{\\partial w_1} \\frac{\\partial s}{\\partial l_1} \\frac{\\partial l_2}{\\partial s} \\frac{\\partial \\ell}{\\partial l_2}\n",
    "$$\n",
    "\n",
    "We update our weights using this gradient with some learning rate $\\alpha$. \n",
    "\n",
    "$$\n",
    "w^\\prime = w - \\alpha \\frac{\\partial \\ell}{\\partial w}\n",
    "$$\n",
    "\n",
    "The learning rate is set such that the weight update steps are small enough that the iterative method settles in a minimum.\n",
    "\n",
    "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
    "\n",
    "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Torch provides a module, `autograd`, for automatically calculating the gradient of tensors. It does this by keeping track of operations performed on tensors. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:52.867509Z",
     "start_time": "2021-05-26T22:26:52.860629Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.8157,  0.2951],\n        [-1.1629, -0.1559]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:53.383436Z",
     "start_time": "2021-05-26T22:26:53.375536Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.6654, 0.0871],\n        [1.3522, 0.0243]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the operation that created `y`, a power operation `PowBackward0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:53.870654Z",
     "start_time": "2021-05-26T22:26:53.867424Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<PowBackward0 object at 0x000001DB6F3A5888>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autgrad module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:54.831912Z",
     "start_time": "2021-05-26T22:26:54.824631Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.5323, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the gradients for `x` and `y` but they are empty currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:55.546143Z",
     "start_time": "2021-05-26T22:26:55.541213Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:56.607560Z",
     "start_time": "2021-05-26T22:26:56.594993Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.4079,  0.1476],\n        [-0.5814, -0.0780]])\ntensor([[ 0.4079,  0.1476],\n        [-0.5814, -0.0780]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These gradients calculations are particularly useful for neural networks. For training we need the gradients of the weights with respect to the cost. With PyTorch, we run data forward through the network to calculate the cost, then, go backwards to calculate the gradients with respect to the cost. Once we have the gradients we can make a gradient descent step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll build a network with `nn.Sequential` here. Only difference from the last part is I'm not actually using softmax on the output, but instead just using the raw output from the last layer. This is because the output from softmax is a probability distribution. Often, the output will have values really close to zero or really close to one. Due to [inaccuracies with representing numbers as floating points](https://docs.python.org/3/tutorial/floatingpoint.html), computations with a softmax output can lose accuracy and become unstable. To get around this, we'll use the raw output, called the **logits**, to calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:56.944759Z",
     "start_time": "2021-05-26T22:26:56.936939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size  = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('logits', nn.Linear(hidden_sizes[1], output_size))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
    "\n",
    "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:26:57.317614Z",
     "start_time": "2021-05-26T22:26:57.313022Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "Below I'll go through one training step and print out the weights and gradients so you can see how it changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:27:07.408433Z",
     "start_time": "2021-05-26T22:27:07.373358Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial weights -  Parameter containing:\ntensor([[-0.0025, -0.0103,  0.0089,  ..., -0.0147,  0.0070, -0.0319],\n        [-0.0178,  0.0116, -0.0290,  ..., -0.0347, -0.0145, -0.0033],\n        [ 0.0188, -0.0068,  0.0307,  ...,  0.0047,  0.0046,  0.0280],\n        ...,\n        [-0.0118, -0.0055, -0.0166,  ...,  0.0219,  0.0288,  0.0004],\n        [-0.0075,  0.0267, -0.0260,  ..., -0.0069, -0.0175, -0.0141],\n        [-0.0209, -0.0045,  0.0087,  ..., -0.0345, -0.0181,  0.0240]],\n       requires_grad=True)\nGradient - tensor([[-0.0057, -0.0057, -0.0057,  ..., -0.0057, -0.0057, -0.0057],\n        [ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n        [ 0.0033,  0.0033,  0.0033,  ...,  0.0033,  0.0033,  0.0033],\n        ...,\n        [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model.fc1.weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(16, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model.fc1.weight.grad)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:27:07.915247Z",
     "start_time": "2021-05-26T22:27:07.908155Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updated weights -  Parameter containing:\ntensor([[-0.0025, -0.0103,  0.0089,  ..., -0.0146,  0.0070, -0.0319],\n        [-0.0178,  0.0115, -0.0291,  ..., -0.0347, -0.0145, -0.0034],\n        [ 0.0187, -0.0069,  0.0307,  ...,  0.0047,  0.0045,  0.0280],\n        ...,\n        [-0.0118, -0.0055, -0.0166,  ...,  0.0219,  0.0288,  0.0005],\n        [-0.0075,  0.0267, -0.0260,  ..., -0.0069, -0.0175, -0.0141],\n        [-0.0209, -0.0045,  0.0087,  ..., -0.0345, -0.0181,  0.0240]],\n       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Updated weights - ', model.fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for real\n",
    "\n",
    "Now we'll put this algorithm into a loop so we can go through all the images. This is fairly straightforward. We'll loop through the mini-batches in our dataset, pass the data through the network to calculate the losses, get the gradients, then run the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:27:08.816179Z",
     "start_time": "2021-05-26T22:27:08.812807Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:27:36.083537Z",
     "start_time": "2021-05-26T22:27:09.280769Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/3\n",
      "\tIteration: 0\t Loss: 0.0577\n",
      "\tIteration: 40\t Loss: 2.2840\n",
      "\tIteration: 80\t Loss: 2.2711\n",
      "\tIteration: 120\t Loss: 2.2571\n",
      "\tIteration: 160\t Loss: 2.2302\n",
      "\tIteration: 200\t Loss: 2.2067\n",
      "\tIteration: 240\t Loss: 2.1861\n",
      "\tIteration: 280\t Loss: 2.1650\n",
      "\tIteration: 320\t Loss: 2.1382\n",
      "\tIteration: 360\t Loss: 2.1110\n",
      "\tIteration: 400\t Loss: 2.0691\n",
      "\tIteration: 440\t Loss: 2.0382\n",
      "\tIteration: 480\t Loss: 1.9988\n",
      "\tIteration: 520\t Loss: 1.9117\n",
      "\tIteration: 560\t Loss: 1.8897\n",
      "\tIteration: 600\t Loss: 1.8738\n",
      "\tIteration: 640\t Loss: 1.7889\n",
      "\tIteration: 680\t Loss: 1.7151\n",
      "\tIteration: 720\t Loss: 1.6406\n",
      "\tIteration: 760\t Loss: 1.5777\n",
      "\tIteration: 800\t Loss: 1.4998\n",
      "\tIteration: 840\t Loss: 1.4850\n",
      "\tIteration: 880\t Loss: 1.3949\n",
      "\tIteration: 920\t Loss: 1.3491\n",
      "\tIteration: 960\t Loss: 1.2896\n",
      "\tIteration: 1000\t Loss: 1.2534\n",
      "\tIteration: 1040\t Loss: 1.2355\n",
      "\tIteration: 1080\t Loss: 1.1764\n",
      "\tIteration: 1120\t Loss: 1.0870\n",
      "\tIteration: 1160\t Loss: 1.0445\n",
      "\tIteration: 1200\t Loss: 0.9945\n",
      "\tIteration: 1240\t Loss: 0.9518\n",
      "\tIteration: 1280\t Loss: 0.9453\n",
      "\tIteration: 1320\t Loss: 0.9041\n",
      "\tIteration: 1360\t Loss: 0.8860\n",
      "\tIteration: 1400\t Loss: 0.8222\n",
      "\tIteration: 1440\t Loss: 0.8097\n",
      "\tIteration: 1480\t Loss: 0.8222\n",
      "\tIteration: 1520\t Loss: 0.7764\n",
      "\tIteration: 1560\t Loss: 0.7360\n",
      "\tIteration: 1600\t Loss: 0.7494\n",
      "\tIteration: 1640\t Loss: 0.7195\n",
      "\tIteration: 1680\t Loss: 0.6920\n",
      "\tIteration: 1720\t Loss: 0.6337\n",
      "\tIteration: 1760\t Loss: 0.6894\n",
      "\tIteration: 1800\t Loss: 0.6425\n",
      "\tIteration: 1840\t Loss: 0.6700\n",
      "\tIteration: 1880\t Loss: 0.6183\n",
      "\tIteration: 1920\t Loss: 0.5918\n",
      "\tIteration: 1960\t Loss: 0.6357\n",
      "\tIteration: 2000\t Loss: 0.6219\n",
      "\tIteration: 2040\t Loss: 0.5793\n",
      "\tIteration: 2080\t Loss: 0.5863\n",
      "\tIteration: 2120\t Loss: 0.5661\n",
      "\tIteration: 2160\t Loss: 0.5755\n",
      "\tIteration: 2200\t Loss: 0.5720\n",
      "\tIteration: 2240\t Loss: 0.5596\n",
      "\tIteration: 2280\t Loss: 0.4885\n",
      "\tIteration: 2320\t Loss: 0.5674\n",
      "\tIteration: 2360\t Loss: 0.5257\n",
      "\tIteration: 2400\t Loss: 0.5657\n",
      "\tIteration: 2440\t Loss: 0.5352\n",
      "\tIteration: 2480\t Loss: 0.4897\n",
      "\tIteration: 2520\t Loss: 0.5018\n",
      "\tIteration: 2560\t Loss: 0.4824\n",
      "\tIteration: 2600\t Loss: 0.4826\n",
      "\tIteration: 2640\t Loss: 0.4864\n",
      "\tIteration: 2680\t Loss: 0.5081\n",
      "\tIteration: 2720\t Loss: 0.4711\n",
      "\tIteration: 2760\t Loss: 0.4340\n",
      "\tIteration: 2800\t Loss: 0.4921\n",
      "\tIteration: 2840\t Loss: 0.4981\n",
      "\tIteration: 2880\t Loss: 0.4576\n",
      "\tIteration: 2920\t Loss: 0.5007\n",
      "\tIteration: 2960\t Loss: 0.4922\n",
      "\tIteration: 3000\t Loss: 0.4059\n",
      "\tIteration: 3040\t Loss: 0.4720\n",
      "\tIteration: 3080\t Loss: 0.3965\n",
      "\tIteration: 3120\t Loss: 0.4665\n",
      "\tIteration: 3160\t Loss: 0.4762\n",
      "\tIteration: 3200\t Loss: 0.4442\n",
      "\tIteration: 3240\t Loss: 0.4404\n",
      "\tIteration: 3280\t Loss: 0.4485\n",
      "\tIteration: 3320\t Loss: 0.4616\n",
      "\tIteration: 3360\t Loss: 0.5090\n",
      "\tIteration: 3400\t Loss: 0.4487\n",
      "\tIteration: 3440\t Loss: 0.4402\n",
      "\tIteration: 3480\t Loss: 0.4475\n",
      "\tIteration: 3520\t Loss: 0.4369\n",
      "\tIteration: 3560\t Loss: 0.4781\n",
      "\tIteration: 3600\t Loss: 0.4293\n",
      "\tIteration: 3640\t Loss: 0.3788\n",
      "\tIteration: 3680\t Loss: 0.4337\n",
      "\tIteration: 3720\t Loss: 0.3853\n",
      "Epoch: 2/3\n",
      "\tIteration: 0\t Loss: 0.0116\n",
      "\tIteration: 40\t Loss: 0.3656\n",
      "\tIteration: 80\t Loss: 0.4009\n",
      "\tIteration: 120\t Loss: 0.4198\n",
      "\tIteration: 160\t Loss: 0.3885\n",
      "\tIteration: 200\t Loss: 0.3667\n",
      "\tIteration: 240\t Loss: 0.4492\n",
      "\tIteration: 280\t Loss: 0.3992\n",
      "\tIteration: 320\t Loss: 0.4674\n",
      "\tIteration: 360\t Loss: 0.3281\n",
      "\tIteration: 400\t Loss: 0.3798\n",
      "\tIteration: 440\t Loss: 0.3196\n",
      "\tIteration: 480\t Loss: 0.3946\n",
      "\tIteration: 520\t Loss: 0.3571\n",
      "\tIteration: 560\t Loss: 0.3929\n",
      "\tIteration: 600\t Loss: 0.3962\n",
      "\tIteration: 640\t Loss: 0.4095\n",
      "\tIteration: 680\t Loss: 0.4173\n",
      "\tIteration: 720\t Loss: 0.3718\n",
      "\tIteration: 760\t Loss: 0.4414\n",
      "\tIteration: 800\t Loss: 0.3402\n",
      "\tIteration: 840\t Loss: 0.4529\n",
      "\tIteration: 880\t Loss: 0.4116\n",
      "\tIteration: 920\t Loss: 0.3959\n",
      "\tIteration: 960\t Loss: 0.3791\n",
      "\tIteration: 1000\t Loss: 0.3982\n",
      "\tIteration: 1040\t Loss: 0.3770\n",
      "\tIteration: 1080\t Loss: 0.3585\n",
      "\tIteration: 1120\t Loss: 0.3190\n",
      "\tIteration: 1160\t Loss: 0.4108\n",
      "\tIteration: 1200\t Loss: 0.3176\n",
      "\tIteration: 1240\t Loss: 0.3890\n",
      "\tIteration: 1280\t Loss: 0.3672\n",
      "\tIteration: 1320\t Loss: 0.3765\n",
      "\tIteration: 1360\t Loss: 0.3278\n",
      "\tIteration: 1400\t Loss: 0.3773\n",
      "\tIteration: 1440\t Loss: 0.3506\n",
      "\tIteration: 1480\t Loss: 0.4490\n",
      "\tIteration: 1520\t Loss: 0.3756\n",
      "\tIteration: 1560\t Loss: 0.4556\n",
      "\tIteration: 1600\t Loss: 0.3744\n",
      "\tIteration: 1640\t Loss: 0.3774\n",
      "\tIteration: 1680\t Loss: 0.3602\n",
      "\tIteration: 1720\t Loss: 0.3722\n",
      "\tIteration: 1760\t Loss: 0.3462\n",
      "\tIteration: 1800\t Loss: 0.3916\n",
      "\tIteration: 1840\t Loss: 0.3391\n",
      "\tIteration: 1880\t Loss: 0.3734\n",
      "\tIteration: 1920\t Loss: 0.4327\n",
      "\tIteration: 1960\t Loss: 0.3388\n",
      "\tIteration: 2000\t Loss: 0.3559\n",
      "\tIteration: 2040\t Loss: 0.3101\n",
      "\tIteration: 2080\t Loss: 0.3900\n",
      "\tIteration: 2120\t Loss: 0.3303\n",
      "\tIteration: 2160\t Loss: 0.3373\n",
      "\tIteration: 2200\t Loss: 0.3726\n",
      "\tIteration: 2240\t Loss: 0.3524\n",
      "\tIteration: 2280\t Loss: 0.3623\n",
      "\tIteration: 2320\t Loss: 0.3401\n",
      "\tIteration: 2360\t Loss: 0.3813\n",
      "\tIteration: 2400\t Loss: 0.3044\n",
      "\tIteration: 2440\t Loss: 0.3256\n",
      "\tIteration: 2480\t Loss: 0.2928\n",
      "\tIteration: 2520\t Loss: 0.3156\n",
      "\tIteration: 2560\t Loss: 0.3937\n",
      "\tIteration: 2600\t Loss: 0.2949\n",
      "\tIteration: 2640\t Loss: 0.3810\n",
      "\tIteration: 2680\t Loss: 0.3502\n",
      "\tIteration: 2720\t Loss: 0.3382\n",
      "\tIteration: 2760\t Loss: 0.3747\n",
      "\tIteration: 2800\t Loss: 0.3290\n",
      "\tIteration: 2840\t Loss: 0.2784\n",
      "\tIteration: 2880\t Loss: 0.3373\n",
      "\tIteration: 2920\t Loss: 0.3771\n",
      "\tIteration: 2960\t Loss: 0.3408\n",
      "\tIteration: 3000\t Loss: 0.3739\n",
      "\tIteration: 3040\t Loss: 0.3459\n",
      "\tIteration: 3080\t Loss: 0.3515\n",
      "\tIteration: 3120\t Loss: 0.3417\n",
      "\tIteration: 3160\t Loss: 0.3416\n",
      "\tIteration: 3200\t Loss: 0.3421\n",
      "\tIteration: 3240\t Loss: 0.3384\n",
      "\tIteration: 3280\t Loss: 0.3315\n",
      "\tIteration: 3320\t Loss: 0.3517\n",
      "\tIteration: 3360\t Loss: 0.3123\n",
      "\tIteration: 3400\t Loss: 0.2668\n",
      "\tIteration: 3440\t Loss: 0.3252\n",
      "\tIteration: 3480\t Loss: 0.3045\n",
      "\tIteration: 3520\t Loss: 0.3128\n",
      "\tIteration: 3560\t Loss: 0.3487\n",
      "\tIteration: 3600\t Loss: 0.2942\n",
      "\tIteration: 3640\t Loss: 0.3268\n",
      "\tIteration: 3680\t Loss: 0.3832\n",
      "\tIteration: 3720\t Loss: 0.3515\n",
      "Epoch: 3/3\n",
      "\tIteration: 0\t Loss: 0.0068\n",
      "\tIteration: 40\t Loss: 0.2565\n",
      "\tIteration: 80\t Loss: 0.3424\n",
      "\tIteration: 120\t Loss: 0.3726\n",
      "\tIteration: 160\t Loss: 0.3153\n",
      "\tIteration: 200\t Loss: 0.3579\n",
      "\tIteration: 240\t Loss: 0.2846\n",
      "\tIteration: 280\t Loss: 0.2940\n",
      "\tIteration: 320\t Loss: 0.3150\n",
      "\tIteration: 360\t Loss: 0.3236\n",
      "\tIteration: 400\t Loss: 0.2606\n",
      "\tIteration: 440\t Loss: 0.3572\n",
      "\tIteration: 480\t Loss: 0.3507\n",
      "\tIteration: 520\t Loss: 0.2812\n",
      "\tIteration: 560\t Loss: 0.3032\n",
      "\tIteration: 600\t Loss: 0.2681\n",
      "\tIteration: 640\t Loss: 0.3664\n",
      "\tIteration: 680\t Loss: 0.3142\n",
      "\tIteration: 720\t Loss: 0.2743\n",
      "\tIteration: 760\t Loss: 0.3071\n",
      "\tIteration: 800\t Loss: 0.2870\n",
      "\tIteration: 840\t Loss: 0.3198\n",
      "\tIteration: 880\t Loss: 0.3809\n",
      "\tIteration: 920\t Loss: 0.2672\n",
      "\tIteration: 960\t Loss: 0.2715\n",
      "\tIteration: 1000\t Loss: 0.3453\n",
      "\tIteration: 1040\t Loss: 0.3556\n",
      "\tIteration: 1080\t Loss: 0.3095\n",
      "\tIteration: 1120\t Loss: 0.3524\n",
      "\tIteration: 1160\t Loss: 0.2332\n",
      "\tIteration: 1200\t Loss: 0.4313\n",
      "\tIteration: 1240\t Loss: 0.2780\n",
      "\tIteration: 1280\t Loss: 0.4294\n",
      "\tIteration: 1320\t Loss: 0.3040\n",
      "\tIteration: 1360\t Loss: 0.2977\n",
      "\tIteration: 1400\t Loss: 0.2852\n",
      "\tIteration: 1440\t Loss: 0.3590\n",
      "\tIteration: 1480\t Loss: 0.2937\n",
      "\tIteration: 1520\t Loss: 0.3022\n",
      "\tIteration: 1560\t Loss: 0.2665\n",
      "\tIteration: 1600\t Loss: 0.2815\n",
      "\tIteration: 1640\t Loss: 0.2941\n",
      "\tIteration: 1680\t Loss: 0.3437\n",
      "\tIteration: 1720\t Loss: 0.2898\n",
      "\tIteration: 1760\t Loss: 0.2774\n",
      "\tIteration: 1800\t Loss: 0.3400\n",
      "\tIteration: 1840\t Loss: 0.2598\n",
      "\tIteration: 1880\t Loss: 0.3537\n",
      "\tIteration: 1920\t Loss: 0.3500\n",
      "\tIteration: 1960\t Loss: 0.2914\n",
      "\tIteration: 2000\t Loss: 0.2934\n",
      "\tIteration: 2040\t Loss: 0.3189\n",
      "\tIteration: 2080\t Loss: 0.3167\n",
      "\tIteration: 2120\t Loss: 0.2941\n",
      "\tIteration: 2160\t Loss: 0.3407\n",
      "\tIteration: 2200\t Loss: 0.3005\n",
      "\tIteration: 2240\t Loss: 0.2989\n",
      "\tIteration: 2280\t Loss: 0.2594\n",
      "\tIteration: 2320\t Loss: 0.3023\n",
      "\tIteration: 2360\t Loss: 0.3835\n",
      "\tIteration: 2400\t Loss: 0.2876\n",
      "\tIteration: 2440\t Loss: 0.2746\n",
      "\tIteration: 2480\t Loss: 0.2835\n",
      "\tIteration: 2520\t Loss: 0.2817\n",
      "\tIteration: 2560\t Loss: 0.3010\n",
      "\tIteration: 2600\t Loss: 0.3122\n",
      "\tIteration: 2640\t Loss: 0.3250\n",
      "\tIteration: 2680\t Loss: 0.3255\n",
      "\tIteration: 2720\t Loss: 0.3212\n",
      "\tIteration: 2760\t Loss: 0.2339\n",
      "\tIteration: 2800\t Loss: 0.3357\n",
      "\tIteration: 2840\t Loss: 0.3390\n",
      "\tIteration: 2880\t Loss: 0.2922\n",
      "\tIteration: 2920\t Loss: 0.2976\n",
      "\tIteration: 2960\t Loss: 0.3126\n",
      "\tIteration: 3000\t Loss: 0.3332\n",
      "\tIteration: 3040\t Loss: 0.3098\n",
      "\tIteration: 3080\t Loss: 0.2727\n",
      "\tIteration: 3120\t Loss: 0.2482\n",
      "\tIteration: 3160\t Loss: 0.2753\n",
      "\tIteration: 3200\t Loss: 0.3235\n",
      "\tIteration: 3240\t Loss: 0.3058\n",
      "\tIteration: 3280\t Loss: 0.3009\n",
      "\tIteration: 3320\t Loss: 0.2538\n",
      "\tIteration: 3360\t Loss: 0.2748\n",
      "\tIteration: 3400\t Loss: 0.2932\n",
      "\tIteration: 3440\t Loss: 0.3138\n",
      "\tIteration: 3480\t Loss: 0.2742\n",
      "\tIteration: 3520\t Loss: 0.2994\n",
      "\tIteration: 3560\t Loss: 0.2924\n",
      "\tIteration: 3600\t Loss: 0.2415\n",
      "\tIteration: 3640\t Loss: 0.2385\n",
      "\tIteration: 3680\t Loss: 0.2870\n",
      "\tIteration: 3720\t Loss: 0.2227\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "print_every = 40\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the network trained, we can check out it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:30:00.206666Z",
     "start_time": "2021-05-26T22:29:59.954325Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x648 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim=1)\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./model.pth\"\n",
    "torch.save(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our network is brilliant. It can accurately predict the digits in our images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">EMNIST Classification: Exercise</h2>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 1:</h3>\n",
    "  <p>Now it's your turn to build a simple network, use any method I've covered so far. In the next notebook, you'll learn how to train a network so it can make good predictions.</p>\n",
    "  <p>Build a network to classify the MNIST images with 3 hidden layers. Use 16 units in the first hidden layer, 32 units in the second layer, and 8 units in the third layer. Each hidden layer should have a ReLU activation function, and use softmax on the output layer.</p>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your network here\n",
    "class Strive_Network(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784,16)\n",
    "        self.fc2 = nn.Linear(16, 32)\n",
    "        self.fc3 = nn.Linear(32,8 )\n",
    "        self.fc4 = nn.Linear(8, 10)\n",
    "        \n",
    "    # Forward pass through the network, returns the output logits\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Strive_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x648 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Run this cell with your model to make sure it works\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 2:</h3>\n",
    "  <p>Train your network implementing the Pytorch training loop and <strong style=\"color:#01ff84\">after each epoch, use the model for predicting the test (validation) MNIST data.</strong></p>\n",
    "  <p>Note: If your model does not fit with the final softmax layer, you can remove this layer.</p>\n",
    "  <p>Hint: <a href=\"https://discuss.pytorch.org/t/training-loop-checking-validation-accuracy/78399\">Training loop checking validation accuracy\n",
    "</a></p>\n",
    "  <p>Research about <code>model.train()</code>, <code>model.eval()</code> and <code>with torch.no_grad()</code> in Pytorch.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/3\n",
      "\tIteration: 0\t Loss: 0.0575\n",
      "\tIteration: 40\t Loss: 2.3035\n",
      "\tIteration: 80\t Loss: 2.3005\n",
      "\tIteration: 120\t Loss: 2.3001\n",
      "\tIteration: 160\t Loss: 2.2964\n",
      "\tIteration: 200\t Loss: 2.2931\n",
      "\tIteration: 240\t Loss: 2.2810\n",
      "\tIteration: 280\t Loss: 2.2372\n",
      "\tIteration: 320\t Loss: 2.1672\n",
      "\tIteration: 360\t Loss: 2.0995\n",
      "\tIteration: 400\t Loss: 2.0879\n",
      "\tIteration: 440\t Loss: 2.0494\n",
      "\tIteration: 480\t Loss: 2.0163\n",
      "\tIteration: 520\t Loss: 2.0171\n",
      "\tIteration: 560\t Loss: 1.9722\n",
      "\tIteration: 600\t Loss: 1.9637\n",
      "\tIteration: 640\t Loss: 1.9810\n",
      "\tIteration: 680\t Loss: 1.9309\n",
      "\tIteration: 720\t Loss: 1.8572\n",
      "\tIteration: 760\t Loss: 1.8959\n",
      "\tIteration: 800\t Loss: 1.8630\n",
      "\tIteration: 840\t Loss: 1.8492\n",
      "\tIteration: 880\t Loss: 1.8493\n",
      "\tIteration: 920\t Loss: 1.8823\n",
      "\tIteration: 960\t Loss: 1.8766\n",
      "\tIteration: 1000\t Loss: 1.8688\n",
      "\tIteration: 1040\t Loss: 1.8771\n",
      "\tIteration: 1080\t Loss: 1.8496\n",
      "\tIteration: 1120\t Loss: 1.8150\n",
      "\tIteration: 1160\t Loss: 1.8276\n",
      "\tIteration: 1200\t Loss: 1.8145\n",
      "\tIteration: 1240\t Loss: 1.8656\n",
      "\tIteration: 1280\t Loss: 1.8299\n",
      "\tIteration: 1320\t Loss: 1.8461\n",
      "\tIteration: 1360\t Loss: 1.8301\n",
      "\tIteration: 1400\t Loss: 1.8083\n",
      "\tIteration: 1440\t Loss: 1.8651\n",
      "\tIteration: 1480\t Loss: 1.8282\n",
      "\tIteration: 1520\t Loss: 1.8397\n",
      "\tIteration: 1560\t Loss: 1.8363\n",
      "\tIteration: 1600\t Loss: 1.8275\n",
      "\tIteration: 1640\t Loss: 1.8317\n",
      "\tIteration: 1680\t Loss: 1.8337\n",
      "\tIteration: 1720\t Loss: 1.8157\n",
      "\tIteration: 1760\t Loss: 1.8003\n",
      "\tIteration: 1800\t Loss: 1.8286\n",
      "\tIteration: 1840\t Loss: 1.8376\n",
      "\tIteration: 1880\t Loss: 1.8389\n",
      "\tIteration: 1920\t Loss: 1.8096\n",
      "\tIteration: 1960\t Loss: 1.8326\n",
      "\tIteration: 2000\t Loss: 1.8066\n",
      "\tIteration: 2040\t Loss: 1.8409\n",
      "\tIteration: 2080\t Loss: 1.8252\n",
      "\tIteration: 2120\t Loss: 1.7902\n",
      "\tIteration: 2160\t Loss: 1.8346\n",
      "\tIteration: 2200\t Loss: 1.8301\n",
      "\tIteration: 2240\t Loss: 1.8177\n",
      "\tIteration: 2280\t Loss: 1.7881\n",
      "\tIteration: 2320\t Loss: 1.8188\n",
      "\tIteration: 2360\t Loss: 1.8133\n",
      "\tIteration: 2400\t Loss: 1.7952\n",
      "\tIteration: 2440\t Loss: 1.8220\n",
      "\tIteration: 2480\t Loss: 1.8015\n",
      "\tIteration: 2520\t Loss: 1.8249\n",
      "\tIteration: 2560\t Loss: 1.7948\n",
      "\tIteration: 2600\t Loss: 1.8023\n",
      "\tIteration: 2640\t Loss: 1.8290\n",
      "\tIteration: 2680\t Loss: 1.8014\n",
      "\tIteration: 2720\t Loss: 1.8118\n",
      "\tIteration: 2760\t Loss: 1.7785\n",
      "\tIteration: 2800\t Loss: 1.8088\n",
      "\tIteration: 2840\t Loss: 1.7964\n",
      "\tIteration: 2880\t Loss: 1.8363\n",
      "\tIteration: 2920\t Loss: 1.8189\n",
      "\tIteration: 2960\t Loss: 1.8046\n",
      "\tIteration: 3000\t Loss: 1.7813\n",
      "\tIteration: 3040\t Loss: 1.7786\n",
      "\tIteration: 3080\t Loss: 1.7844\n",
      "\tIteration: 3120\t Loss: 1.7964\n",
      "\tIteration: 3160\t Loss: 1.7406\n",
      "\tIteration: 3200\t Loss: 1.7715\n",
      "\tIteration: 3240\t Loss: 1.7507\n",
      "\tIteration: 3280\t Loss: 1.7464\n",
      "\tIteration: 3320\t Loss: 1.7253\n",
      "\tIteration: 3360\t Loss: 1.7374\n",
      "\tIteration: 3400\t Loss: 1.7482\n",
      "\tIteration: 3440\t Loss: 1.7635\n",
      "\tIteration: 3480\t Loss: 1.7332\n",
      "\tIteration: 3520\t Loss: 1.7447\n",
      "\tIteration: 3560\t Loss: 1.7342\n",
      "\tIteration: 3600\t Loss: 1.7420\n",
      "\tIteration: 3640\t Loss: 1.7042\n",
      "\tIteration: 3680\t Loss: 1.7318\n",
      "\tIteration: 3720\t Loss: 1.7427\n",
      "Accuracy of the network: 73 %\n",
      "Epoch: 2/3\n",
      "\tIteration: 0\t Loss: 0.0427\n",
      "\tIteration: 40\t Loss: 1.7791\n",
      "\tIteration: 80\t Loss: 1.7518\n",
      "\tIteration: 120\t Loss: 1.7231\n",
      "\tIteration: 160\t Loss: 1.7270\n",
      "\tIteration: 200\t Loss: 1.7277\n",
      "\tIteration: 240\t Loss: 1.7319\n",
      "\tIteration: 280\t Loss: 1.7395\n",
      "\tIteration: 320\t Loss: 1.7256\n",
      "\tIteration: 360\t Loss: 1.7398\n",
      "\tIteration: 400\t Loss: 1.7342\n",
      "\tIteration: 440\t Loss: 1.7395\n",
      "\tIteration: 480\t Loss: 1.7066\n",
      "\tIteration: 520\t Loss: 1.7115\n",
      "\tIteration: 560\t Loss: 1.7164\n",
      "\tIteration: 600\t Loss: 1.7189\n",
      "\tIteration: 640\t Loss: 1.7323\n",
      "\tIteration: 680\t Loss: 1.7117\n",
      "\tIteration: 720\t Loss: 1.7294\n",
      "\tIteration: 760\t Loss: 1.7168\n",
      "\tIteration: 800\t Loss: 1.7214\n",
      "\tIteration: 840\t Loss: 1.7010\n",
      "\tIteration: 880\t Loss: 1.7313\n",
      "\tIteration: 920\t Loss: 1.7386\n",
      "\tIteration: 960\t Loss: 1.7140\n",
      "\tIteration: 1000\t Loss: 1.7360\n",
      "\tIteration: 1040\t Loss: 1.7393\n",
      "\tIteration: 1080\t Loss: 1.7488\n",
      "\tIteration: 1120\t Loss: 1.7133\n",
      "\tIteration: 1160\t Loss: 1.7758\n",
      "\tIteration: 1200\t Loss: 1.7487\n",
      "\tIteration: 1240\t Loss: 1.7321\n",
      "\tIteration: 1280\t Loss: 1.7020\n",
      "\tIteration: 1320\t Loss: 1.7418\n",
      "\tIteration: 1360\t Loss: 1.7217\n",
      "\tIteration: 1400\t Loss: 1.7561\n",
      "\tIteration: 1440\t Loss: 1.7240\n",
      "\tIteration: 1480\t Loss: 1.7682\n",
      "\tIteration: 1520\t Loss: 1.7310\n",
      "\tIteration: 1560\t Loss: 1.7346\n",
      "\tIteration: 1600\t Loss: 1.7258\n",
      "\tIteration: 1640\t Loss: 1.7482\n",
      "\tIteration: 1680\t Loss: 1.7325\n",
      "\tIteration: 1720\t Loss: 1.7478\n",
      "\tIteration: 1760\t Loss: 1.7218\n",
      "\tIteration: 1800\t Loss: 1.7109\n",
      "\tIteration: 1840\t Loss: 1.7492\n",
      "\tIteration: 1880\t Loss: 1.7114\n",
      "\tIteration: 1920\t Loss: 1.7309\n",
      "\tIteration: 1960\t Loss: 1.7502\n",
      "\tIteration: 2000\t Loss: 1.7178\n",
      "\tIteration: 2040\t Loss: 1.7129\n",
      "\tIteration: 2080\t Loss: 1.7214\n",
      "\tIteration: 2120\t Loss: 1.6956\n",
      "\tIteration: 2160\t Loss: 1.7319\n",
      "\tIteration: 2200\t Loss: 1.6993\n",
      "\tIteration: 2240\t Loss: 1.7215\n",
      "\tIteration: 2280\t Loss: 1.7237\n",
      "\tIteration: 2320\t Loss: 1.7324\n",
      "\tIteration: 2360\t Loss: 1.7085\n",
      "\tIteration: 2400\t Loss: 1.7136\n",
      "\tIteration: 2440\t Loss: 1.7379\n",
      "\tIteration: 2480\t Loss: 1.7461\n",
      "\tIteration: 2520\t Loss: 1.7334\n",
      "\tIteration: 2560\t Loss: 1.7068\n",
      "\tIteration: 2600\t Loss: 1.7389\n",
      "\tIteration: 2640\t Loss: 1.7091\n",
      "\tIteration: 2680\t Loss: 1.7094\n",
      "\tIteration: 2720\t Loss: 1.7288\n",
      "\tIteration: 2760\t Loss: 1.7231\n",
      "\tIteration: 2800\t Loss: 1.7149\n",
      "\tIteration: 2840\t Loss: 1.7097\n",
      "\tIteration: 2880\t Loss: 1.6709\n",
      "\tIteration: 2920\t Loss: 1.7427\n",
      "\tIteration: 2960\t Loss: 1.7029\n",
      "\tIteration: 3000\t Loss: 1.6908\n",
      "\tIteration: 3040\t Loss: 1.6874\n",
      "\tIteration: 3080\t Loss: 1.7057\n",
      "\tIteration: 3120\t Loss: 1.6851\n",
      "\tIteration: 3160\t Loss: 1.6829\n",
      "\tIteration: 3200\t Loss: 1.6950\n",
      "\tIteration: 3240\t Loss: 1.6874\n",
      "\tIteration: 3280\t Loss: 1.6732\n",
      "\tIteration: 3320\t Loss: 1.7000\n",
      "\tIteration: 3360\t Loss: 1.6943\n",
      "\tIteration: 3400\t Loss: 1.6759\n",
      "\tIteration: 3440\t Loss: 1.6558\n",
      "\tIteration: 3480\t Loss: 1.7054\n",
      "\tIteration: 3520\t Loss: 1.7017\n",
      "\tIteration: 3560\t Loss: 1.6879\n",
      "\tIteration: 3600\t Loss: 1.7150\n",
      "\tIteration: 3640\t Loss: 1.6766\n",
      "\tIteration: 3680\t Loss: 1.6826\n",
      "\tIteration: 3720\t Loss: 1.6959\n",
      "Accuracy of the network: 80 %\n",
      "Epoch: 3/3\n",
      "\tIteration: 0\t Loss: 0.0430\n",
      "\tIteration: 40\t Loss: 1.6554\n",
      "\tIteration: 80\t Loss: 1.6470\n",
      "\tIteration: 120\t Loss: 1.7155\n",
      "\tIteration: 160\t Loss: 1.6855\n",
      "\tIteration: 200\t Loss: 1.6914\n",
      "\tIteration: 240\t Loss: 1.6986\n",
      "\tIteration: 280\t Loss: 1.6951\n",
      "\tIteration: 320\t Loss: 1.6985\n",
      "\tIteration: 360\t Loss: 1.6570\n",
      "\tIteration: 400\t Loss: 1.6895\n",
      "\tIteration: 440\t Loss: 1.7211\n",
      "\tIteration: 480\t Loss: 1.7016\n",
      "\tIteration: 520\t Loss: 1.6780\n",
      "\tIteration: 560\t Loss: 1.6695\n",
      "\tIteration: 600\t Loss: 1.6695\n",
      "\tIteration: 640\t Loss: 1.6952\n",
      "\tIteration: 680\t Loss: 1.6462\n",
      "\tIteration: 720\t Loss: 1.6729\n",
      "\tIteration: 760\t Loss: 1.6740\n",
      "\tIteration: 800\t Loss: 1.6762\n",
      "\tIteration: 840\t Loss: 1.6838\n",
      "\tIteration: 880\t Loss: 1.6699\n",
      "\tIteration: 920\t Loss: 1.6826\n",
      "\tIteration: 960\t Loss: 1.6489\n",
      "\tIteration: 1000\t Loss: 1.7207\n",
      "\tIteration: 1040\t Loss: 1.6939\n",
      "\tIteration: 1080\t Loss: 1.6792\n",
      "\tIteration: 1120\t Loss: 1.6673\n",
      "\tIteration: 1160\t Loss: 1.6704\n",
      "\tIteration: 1200\t Loss: 1.7012\n",
      "\tIteration: 1240\t Loss: 1.7130\n",
      "\tIteration: 1280\t Loss: 1.6547\n",
      "\tIteration: 1320\t Loss: 1.6859\n",
      "\tIteration: 1360\t Loss: 1.6595\n",
      "\tIteration: 1400\t Loss: 1.6726\n",
      "\tIteration: 1440\t Loss: 1.6724\n",
      "\tIteration: 1480\t Loss: 1.6708\n",
      "\tIteration: 1520\t Loss: 1.6704\n",
      "\tIteration: 1560\t Loss: 1.6504\n",
      "\tIteration: 1600\t Loss: 1.6438\n",
      "\tIteration: 1640\t Loss: 1.6991\n",
      "\tIteration: 1680\t Loss: 1.6914\n",
      "\tIteration: 1720\t Loss: 1.6698\n",
      "\tIteration: 1760\t Loss: 1.7193\n",
      "\tIteration: 1800\t Loss: 1.6558\n",
      "\tIteration: 1840\t Loss: 1.6628\n",
      "\tIteration: 1880\t Loss: 1.6975\n",
      "\tIteration: 1920\t Loss: 1.6629\n",
      "\tIteration: 1960\t Loss: 1.6622\n",
      "\tIteration: 2000\t Loss: 1.6434\n",
      "\tIteration: 2040\t Loss: 1.6694\n",
      "\tIteration: 2080\t Loss: 1.6391\n",
      "\tIteration: 2120\t Loss: 1.6452\n",
      "\tIteration: 2160\t Loss: 1.6728\n",
      "\tIteration: 2200\t Loss: 1.6713\n",
      "\tIteration: 2240\t Loss: 1.6472\n",
      "\tIteration: 2280\t Loss: 1.6636\n",
      "\tIteration: 2320\t Loss: 1.6694\n",
      "\tIteration: 2360\t Loss: 1.6675\n",
      "\tIteration: 2400\t Loss: 1.6329\n",
      "\tIteration: 2440\t Loss: 1.6520\n",
      "\tIteration: 2480\t Loss: 1.6847\n",
      "\tIteration: 2520\t Loss: 1.6503\n",
      "\tIteration: 2560\t Loss: 1.6605\n",
      "\tIteration: 2600\t Loss: 1.6959\n",
      "\tIteration: 2640\t Loss: 1.6506\n",
      "\tIteration: 2680\t Loss: 1.6557\n",
      "\tIteration: 2720\t Loss: 1.6334\n",
      "\tIteration: 2760\t Loss: 1.6836\n",
      "\tIteration: 2800\t Loss: 1.6674\n",
      "\tIteration: 2840\t Loss: 1.6831\n",
      "\tIteration: 2880\t Loss: 1.6652\n",
      "\tIteration: 2920\t Loss: 1.6658\n",
      "\tIteration: 2960\t Loss: 1.6681\n",
      "\tIteration: 3000\t Loss: 1.6627\n",
      "\tIteration: 3040\t Loss: 1.6846\n",
      "\tIteration: 3080\t Loss: 1.6769\n",
      "\tIteration: 3120\t Loss: 1.6571\n",
      "\tIteration: 3160\t Loss: 1.7126\n",
      "\tIteration: 3200\t Loss: 1.6289\n",
      "\tIteration: 3240\t Loss: 1.6507\n",
      "\tIteration: 3280\t Loss: 1.6472\n",
      "\tIteration: 3320\t Loss: 1.6679\n",
      "\tIteration: 3360\t Loss: 1.6575\n",
      "\tIteration: 3400\t Loss: 1.6323\n",
      "\tIteration: 3440\t Loss: 1.6520\n",
      "\tIteration: 3480\t Loss: 1.6467\n",
      "\tIteration: 3520\t Loss: 1.6582\n",
      "\tIteration: 3560\t Loss: 1.6439\n",
      "\tIteration: 3600\t Loss: 1.6628\n",
      "\tIteration: 3640\t Loss: 1.6943\n",
      "\tIteration: 3680\t Loss: 1.6764\n",
      "\tIteration: 3720\t Loss: 1.6598\n",
      "Accuracy of the network: 78 %\n"
     ]
    }
   ],
   "source": [
    "## TODO: Your training loop here\n",
    "epochs = 3\n",
    "print_every = 40\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(iter(testloader)):\n",
    "            images.resize_(images.size()[0], 784)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x648 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Run this cell with your model to make sure it works and predicts well for the validation data\n",
    "images, labels = next(iter(testloader))\n",
    "images.resize_(images.shape[0],1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 3:</h3>\n",
    "  <p>Write the code for adding <strong style=\"color:#01ff84\">Early Stopping with patience = 2</strong> to the training loop from scratch.</p>\n",
    "  <p><strong style=\"color:#01ff84\">Hint:</strong> Monitor the Validation loss every epoch, and if in 2 epochs, the validation loss does not improve, stop the training loop with <code>break</code>.</p>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/5\n",
      "\tIteration: 0\t Loss: 0.0412\n",
      "\tIteration: 40\t Loss: 1.5941\n",
      "\tIteration: 80\t Loss: 1.5747\n",
      "\tIteration: 120\t Loss: 1.5624\n",
      "\tIteration: 160\t Loss: 1.5691\n",
      "\tIteration: 200\t Loss: 1.5825\n",
      "\tIteration: 240\t Loss: 1.6226\n",
      "\tIteration: 280\t Loss: 1.6011\n",
      "\tIteration: 320\t Loss: 1.5766\n",
      "\tIteration: 360\t Loss: 1.5690\n",
      "\tIteration: 400\t Loss: 1.6596\n",
      "\tIteration: 440\t Loss: 1.6236\n",
      "\tIteration: 480\t Loss: 1.5961\n",
      "\tIteration: 520\t Loss: 1.5918\n",
      "\tIteration: 560\t Loss: 1.6314\n",
      "\tIteration: 600\t Loss: 1.5954\n",
      "\tIteration: 640\t Loss: 1.5536\n",
      "\tIteration: 680\t Loss: 1.5903\n",
      "\tIteration: 720\t Loss: 1.6133\n",
      "\tIteration: 760\t Loss: 1.5953\n",
      "\tIteration: 800\t Loss: 1.5702\n",
      "\tIteration: 840\t Loss: 1.5743\n",
      "\tIteration: 880\t Loss: 1.5953\n",
      "\tIteration: 920\t Loss: 1.5875\n",
      "\tIteration: 960\t Loss: 1.6221\n",
      "\tIteration: 1000\t Loss: 1.5977\n",
      "\tIteration: 1040\t Loss: 1.6057\n",
      "\tIteration: 1080\t Loss: 1.5884\n",
      "\tIteration: 1120\t Loss: 1.5746\n",
      "\tIteration: 1160\t Loss: 1.5808\n",
      "\tIteration: 1200\t Loss: 1.5804\n",
      "\tIteration: 1240\t Loss: 1.6025\n",
      "\tIteration: 1280\t Loss: 1.6148\n",
      "\tIteration: 1320\t Loss: 1.5949\n",
      "\tIteration: 1360\t Loss: 1.5934\n",
      "\tIteration: 1400\t Loss: 1.5736\n",
      "\tIteration: 1440\t Loss: 1.6079\n",
      "\tIteration: 1480\t Loss: 1.5694\n",
      "\tIteration: 1520\t Loss: 1.5805\n",
      "\tIteration: 1560\t Loss: 1.6057\n",
      "\tIteration: 1600\t Loss: 1.5987\n",
      "\tIteration: 1640\t Loss: 1.5958\n",
      "\tIteration: 1680\t Loss: 1.5845\n",
      "\tIteration: 1720\t Loss: 1.5566\n",
      "\tIteration: 1760\t Loss: 1.5732\n",
      "\tIteration: 1800\t Loss: 1.6078\n",
      "\tIteration: 1840\t Loss: 1.6257\n",
      "\tIteration: 1880\t Loss: 1.6331\n",
      "\tIteration: 1920\t Loss: 1.5847\n",
      "\tIteration: 1960\t Loss: 1.5661\n",
      "\tIteration: 2000\t Loss: 1.6072\n",
      "\tIteration: 2040\t Loss: 1.5932\n",
      "\tIteration: 2080\t Loss: 1.6022\n",
      "\tIteration: 2120\t Loss: 1.5462\n",
      "\tIteration: 2160\t Loss: 1.5643\n",
      "\tIteration: 2200\t Loss: 1.5660\n",
      "\tIteration: 2240\t Loss: 1.5816\n",
      "\tIteration: 2280\t Loss: 1.5988\n",
      "\tIteration: 2320\t Loss: 1.5953\n",
      "\tIteration: 2360\t Loss: 1.6101\n",
      "\tIteration: 2400\t Loss: 1.5911\n",
      "\tIteration: 2440\t Loss: 1.6391\n",
      "\tIteration: 2480\t Loss: 1.6538\n",
      "\tIteration: 2520\t Loss: 1.5871\n",
      "\tIteration: 2560\t Loss: 1.5941\n",
      "\tIteration: 2600\t Loss: 1.5724\n",
      "\tIteration: 2640\t Loss: 1.6069\n",
      "\tIteration: 2680\t Loss: 1.5962\n",
      "\tIteration: 2720\t Loss: 1.5973\n",
      "\tIteration: 2760\t Loss: 1.5957\n",
      "\tIteration: 2800\t Loss: 1.6053\n",
      "\tIteration: 2840\t Loss: 1.6674\n",
      "\tIteration: 2880\t Loss: 1.6043\n",
      "\tIteration: 2920\t Loss: 1.5756\n",
      "\tIteration: 2960\t Loss: 1.6153\n",
      "\tIteration: 3000\t Loss: 1.5920\n",
      "\tIteration: 3040\t Loss: 1.6890\n",
      "\tIteration: 3080\t Loss: 1.5582\n",
      "\tIteration: 3120\t Loss: 1.6133\n",
      "\tIteration: 3160\t Loss: 1.5699\n",
      "\tIteration: 3200\t Loss: 1.6134\n",
      "\tIteration: 3240\t Loss: 1.5597\n",
      "\tIteration: 3280\t Loss: 1.6354\n",
      "\tIteration: 3320\t Loss: 1.6024\n",
      "\tIteration: 3360\t Loss: 1.6186\n",
      "\tIteration: 3400\t Loss: 1.6085\n",
      "\tIteration: 3440\t Loss: 1.6180\n",
      "\tIteration: 3480\t Loss: 1.5941\n",
      "\tIteration: 3520\t Loss: 1.5928\n",
      "\tIteration: 3560\t Loss: 1.5716\n",
      "\tIteration: 3600\t Loss: 1.6150\n",
      "\tIteration: 3640\t Loss: 1.5921\n",
      "\tIteration: 3680\t Loss: 1.6220\n",
      "\tIteration: 3720\t Loss: 1.5694\n",
      "Accuracy of the network: 87 %\n",
      "Validation loss: 988.8927297592163\n",
      "Epoch: 2/5\n",
      "\tIteration: 0\t Loss: 0.0367\n",
      "\tIteration: 40\t Loss: 1.5748\n",
      "\tIteration: 80\t Loss: 1.5797\n",
      "\tIteration: 120\t Loss: 1.5886\n",
      "\tIteration: 160\t Loss: 1.6031\n",
      "\tIteration: 200\t Loss: 1.5974\n",
      "\tIteration: 240\t Loss: 1.5697\n",
      "\tIteration: 280\t Loss: 1.6190\n",
      "\tIteration: 320\t Loss: 1.6156\n",
      "\tIteration: 360\t Loss: 1.5871\n",
      "\tIteration: 400\t Loss: 1.6306\n",
      "\tIteration: 440\t Loss: 1.5816\n",
      "\tIteration: 480\t Loss: 1.5636\n",
      "\tIteration: 520\t Loss: 1.6367\n",
      "\tIteration: 560\t Loss: 1.6249\n",
      "\tIteration: 600\t Loss: 1.6109\n",
      "\tIteration: 640\t Loss: 1.6096\n",
      "\tIteration: 680\t Loss: 1.6363\n",
      "\tIteration: 720\t Loss: 1.6145\n",
      "\tIteration: 760\t Loss: 1.6427\n",
      "\tIteration: 800\t Loss: 1.6672\n",
      "\tIteration: 840\t Loss: 1.7075\n",
      "\tIteration: 880\t Loss: 1.6610\n",
      "\tIteration: 920\t Loss: 1.6476\n",
      "\tIteration: 960\t Loss: 1.5980\n",
      "\tIteration: 1000\t Loss: 1.6039\n",
      "\tIteration: 1040\t Loss: 1.5911\n",
      "\tIteration: 1080\t Loss: 1.5898\n",
      "\tIteration: 1120\t Loss: 1.6071\n",
      "\tIteration: 1160\t Loss: 1.5775\n",
      "\tIteration: 1200\t Loss: 1.6490\n",
      "\tIteration: 1240\t Loss: 1.6130\n",
      "\tIteration: 1280\t Loss: 1.6401\n",
      "\tIteration: 1320\t Loss: 1.6931\n",
      "\tIteration: 1360\t Loss: 1.5703\n",
      "\tIteration: 1400\t Loss: 1.5933\n",
      "\tIteration: 1440\t Loss: 1.6221\n",
      "\tIteration: 1480\t Loss: 1.5857\n",
      "\tIteration: 1520\t Loss: 1.6078\n",
      "\tIteration: 1560\t Loss: 1.6608\n",
      "\tIteration: 1600\t Loss: 1.6470\n",
      "\tIteration: 1640\t Loss: 1.5783\n",
      "\tIteration: 1680\t Loss: 1.5980\n",
      "\tIteration: 1720\t Loss: 1.6372\n",
      "\tIteration: 1760\t Loss: 1.6526\n",
      "\tIteration: 1800\t Loss: 1.6311\n",
      "\tIteration: 1840\t Loss: 1.6103\n",
      "\tIteration: 1880\t Loss: 1.6003\n",
      "\tIteration: 1920\t Loss: 1.6278\n",
      "\tIteration: 1960\t Loss: 1.6270\n",
      "\tIteration: 2000\t Loss: 1.6225\n",
      "\tIteration: 2040\t Loss: 1.6720\n",
      "\tIteration: 2080\t Loss: 1.5733\n",
      "\tIteration: 2120\t Loss: 1.5972\n",
      "\tIteration: 2160\t Loss: 1.5818\n",
      "\tIteration: 2200\t Loss: 1.5624\n",
      "\tIteration: 2240\t Loss: 1.6156\n",
      "\tIteration: 2280\t Loss: 1.5931\n",
      "\tIteration: 2320\t Loss: 1.6422\n",
      "\tIteration: 2360\t Loss: 1.6104\n",
      "\tIteration: 2400\t Loss: 1.6075\n",
      "\tIteration: 2440\t Loss: 1.6050\n",
      "\tIteration: 2480\t Loss: 1.5911\n",
      "\tIteration: 2520\t Loss: 1.5754\n",
      "\tIteration: 2560\t Loss: 1.5760\n",
      "\tIteration: 2600\t Loss: 1.6751\n",
      "\tIteration: 2640\t Loss: 1.7044\n",
      "\tIteration: 2680\t Loss: 1.6434\n",
      "\tIteration: 2720\t Loss: 1.6192\n",
      "\tIteration: 2760\t Loss: 1.6549\n",
      "\tIteration: 2800\t Loss: 1.6363\n",
      "\tIteration: 2840\t Loss: 1.6240\n",
      "\tIteration: 2880\t Loss: 1.6134\n",
      "\tIteration: 2920\t Loss: 1.6410\n",
      "\tIteration: 2960\t Loss: 1.7225\n",
      "\tIteration: 3000\t Loss: 1.6204\n",
      "\tIteration: 3040\t Loss: 1.5895\n",
      "\tIteration: 3080\t Loss: 1.5845\n",
      "\tIteration: 3120\t Loss: 1.5711\n",
      "\tIteration: 3160\t Loss: 1.5803\n",
      "\tIteration: 3200\t Loss: 1.6121\n",
      "\tIteration: 3240\t Loss: 1.6240\n",
      "\tIteration: 3280\t Loss: 1.5782\n",
      "\tIteration: 3320\t Loss: 1.6207\n",
      "\tIteration: 3360\t Loss: 1.6380\n",
      "\tIteration: 3400\t Loss: 1.6028\n",
      "\tIteration: 3440\t Loss: 1.6636\n",
      "\tIteration: 3480\t Loss: 1.5869\n",
      "\tIteration: 3520\t Loss: 1.6370\n",
      "\tIteration: 3560\t Loss: 1.7316\n",
      "\tIteration: 3600\t Loss: 1.6384\n",
      "\tIteration: 3640\t Loss: 1.5994\n",
      "\tIteration: 3680\t Loss: 1.6071\n",
      "\tIteration: 3720\t Loss: 1.6077\n",
      "Accuracy of the network: 86 %\n",
      "Validation loss: 998.0568175315857\n"
     ]
    }
   ],
   "source": [
    "## TODO: Your training loop here\n",
    "best_validation_loss = np.inf\n",
    "epochs = 5\n",
    "print_every = 40\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    running_validation_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(iter(testloader)):\n",
    "            images.resize_(images.size()[0], 784)\n",
    "            output = model(images)\n",
    "            running_validation_loss += criterion(output, labels).item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    print(f'Validation loss: {running_validation_loss}')\n",
    "    if best_validation_loss > running_validation_loss:\n",
    "        best_validation_loss = running_validation_loss\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Optional:</h3>\n",
    "  <p>Don't you want to use MNIST? Try EMNIST instead! Maybe using the first 10 letters of the alphabet!</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:35:26.981584Z",
     "start_time": "2021-05-26T22:35:26.954522Z"
    }
   },
   "outputs": [],
   "source": [
    "# we will need a custom visualization function\n",
    "def view_classify_emnist(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(list(\"abcdefghij\"), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:50:57.571260Z",
     "start_time": "2021-05-26T22:50:57.322172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data (Preprocessing)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
    "def my_collate(batch):\n",
    "    modified_batch = []\n",
    "    for item in batch:\n",
    "        image, label = item\n",
    "        if label < 10: # only the first ten letters\n",
    "            modified_batch.append(item)\n",
    "    return torch.utils.data._utils.collate.default_collate(modified_batch)\n",
    "\n",
    "\n",
    "# Download and load the training data\n",
    "trainset    = datasets.EMNIST('EMNIST_data/', split=\"letters\", download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "# Download and load the test data\n",
    "testset    = datasets.EMNIST('EMNIST_data/', split=\"letters\", download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:51:02.493175Z",
     "start_time": "2021-05-26T22:51:02.464301Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:51:03.118421Z",
     "start_time": "2021-05-26T22:51:02.978678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[5].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T22:51:06.653639Z",
     "start_time": "2021-05-26T22:51:06.647991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 6, 7, 5, 1, 9, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd050a93f2fecfd00da27f8930a2c1c74e92db967b2162384b3e8848f4306dc0d4b",
   "display_name": "Python 3.7.10 64-bit ('deeplearner': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "metadata": {
   "interpreter": {
    "hash": "50a93f2fecfd00da27f8930a2c1c74e92db967b2162384b3e8848f4306dc0d4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}