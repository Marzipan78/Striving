{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\grequests.py:22: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\urllib3\\\\util\\\\__init__.py)', 'urllib3.util.ssl_ (C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\urllib3\\\\util\\\\ssl_.py)']. \n",
      "  curious_george.patch_all(thread=False, select=False)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gevent\\hub.py:158: UserWarning: libuv only supports millisecond timer resolution; all times less will be set to 1 ms\n",
      "  with loop.timer(seconds, ref=ref) as t:\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import requests\n",
    "import grequests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "base_url = \"https://www.goodreads.com/list/show/264.Books_That_Everyone_Should_Read_At_Least_Once?page={}\"\n",
    "\n",
    "\n",
    "def get_pages_links(string, index):\n",
    "    links = []\n",
    "    for index in range(1,index):\n",
    "        url = string.format(index)\n",
    "        links.append(url)\n",
    "    return links\n",
    "    \n",
    "def grequest_page(strings, index):\n",
    "    reqs = (grequests.get(string) for string in strings)\n",
    "    resp = grequests.imap(reqs, grequests.Pool(index))\n",
    "    return resp\n",
    "def request_single_page(string):\n",
    "    res = requests.get(string)\n",
    "    return res\n",
    "\n",
    "def request_soup(page):\n",
    "    soup = BeautifulSoup(page.content ,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def close_request(request_page):\n",
    "    request_page.close()\n",
    "    return\n",
    "\n",
    "def read_books_links(page_soup):\n",
    "    Links = []\n",
    "    books = page_soup.find_all('tr')\n",
    "    for book in books:\n",
    "        info_book = book.find('a', class_ = 'bookTitle')\n",
    "        book_link = \"https://www.goodreads.com{}\".format(info_book['href'])\n",
    "        Links.append(book_link)    \n",
    "    return Links\n",
    "def get_bookslink(index):\n",
    "    Links_res = []\n",
    "    page = grequest_page(get_pages_links(base_url, index), index)\n",
    "    for r in page: \n",
    "        soup = request_soup(r)\n",
    "        Links_res = Links_res + read_books_links(soup)\n",
    "    print(len(Links_res))\n",
    "    with open(\"Links_for_each_book.txt\", \"w\") as output:\n",
    "        output.write(str(Links_res))\n",
    "    return Links_res\n",
    "\n",
    "def get_pubDate(data):  \n",
    "    if data.find('nobr', class_ = \"greyText\") is not None:\n",
    "        firstPub = data.find('nobr', class_ = \"greyText\").text\n",
    "        firstPub = firstPub.strip()\n",
    "        firstPub = firstPub[-5:]\n",
    "        firstPub = firstPub.replace(\")\",\"\")\n",
    "        return firstPub\n",
    "    else: return np.nan\n",
    "\n",
    "def get_genres(book):\n",
    "    genres = []\n",
    "    names = book.find_all('a', class_=\"actionLinkLite bookPageGenreLink\")\n",
    "    if names is not None:\n",
    "        for name in names:\n",
    "          genres.append(name.get_text())  \n",
    "        return genres\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def get_awards(book):\n",
    "    awards_list = []    \n",
    "    names = book.find_all('a', class_=\"award\")\n",
    "    if names is not None:\n",
    "        for name in names:\n",
    "            awards_list.append(name.get_text())\n",
    "        return awards_list\n",
    "    else: \n",
    "        return np.nan\n",
    "    \n",
    "def get_places(book):\n",
    "    return\n",
    "\n",
    "def get_info_book(page_soup, link, index):\n",
    "    book = page_soup.find_all('div', class_ = 'mainContentFloat')\n",
    "    for data in book:\n",
    "        #TITLE of the Book\n",
    "        title = data.find('h1')\n",
    "        if title is not None:\n",
    "            title = title.text\n",
    "            title = title.strip()\n",
    "        else: title = np.nan\n",
    "        #AUTHOR of the book\n",
    "        author = data.find('a', class_ = \"authorName\")\n",
    "        if author is not None:\n",
    "            author = author.text\n",
    "        else: author = np.nan\n",
    "        #RATING COUNT of the book\n",
    "        ratingCount = data.find('meta', itemprop = \"ratingCount\")\n",
    "        if ratingCount is not None:\n",
    "            ratingCount = ratingCount.text\n",
    "            ratingCount = re.sub(\"\\D\", \"\", ratingCount)\n",
    "        else: ratingCount = np.nan\n",
    "        #REVIEW COUNT of the book\n",
    "        reviewCount = data.find('meta', itemprop = \"reviewCount\")\n",
    "        if reviewCount is not None:\n",
    "            reviewCount = reviewCount.text\n",
    "            reviewCount = re.sub(\"\\D\", \"\", reviewCount)\n",
    "        else: reviewCount = np.nan\n",
    "        #RATING VALUE of the book\n",
    "        ratingValue = data.find('span', itemprop = \"ratingValue\")\n",
    "        if ratingValue is not None:\n",
    "            ratingValue = ratingValue.text\n",
    "            ratingValue = ratingValue.strip()\n",
    "        else: ratingValue = np.nan\n",
    "        #NUMBER OF PAGES of the book\n",
    "        numberOfPages = data.find('span', itemprop = \"numberOfPages\")\n",
    "        if numberOfPages is not None:\n",
    "            numberOfPages = numberOfPages.text\n",
    "            numberOfPages = re.sub(\"\\D\", \"\", numberOfPages)\n",
    "        else: numberOfPages = np.nan\n",
    "        #YEAR OF FIRST PUBBLICATION of the book\n",
    "        firstPub = get_pubDate(data)\n",
    "        #CHECK IF IT IS A SERIES OR NOT\n",
    "        series = data.find('div', id = \"bookDataBox\").text\n",
    "        if \"Series\" in series: \n",
    "            series = '1'\n",
    "        else: \n",
    "            series = '0'\n",
    "        #GENRES of the book\n",
    "        genreList = get_genres(data)\n",
    "        #AWARDS of the book\n",
    "        awards = get_awards(data)\n",
    "        #PLACES of the book\n",
    " \n",
    "        \n",
    "        #Return Dictionary\n",
    "        Book_dict = {\n",
    "                \"url\":link,\n",
    "                \"title\":title,\n",
    "                \"author\":author,\n",
    "                \"num_rating\":ratingCount,\n",
    "                \"num_review\":reviewCount,\n",
    "                \"avg_rating\":ratingValue,\n",
    "                \"num_pages\":numberOfPages,\n",
    "                \"original_publish_year\":firstPub,\n",
    "                \"series\":series,\n",
    "                \"genres\":genreList,\n",
    "                \"awards\":awards}\n",
    "        #print(index,\"  \",link,\"\\n__\",title,author,ratingCount, reviewCount, ratingValue, numberOfPages,firstPub,           series, genreList, awards,\"\\n\\n\")\n",
    "        return Book_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_csv(index):\n",
    "    links = get_bookslink(index + 1)\n",
    "    res_dict = {}\n",
    "    i = 1\n",
    "    page = grequest_page(links, index + 1)\n",
    "    df = pd.DataFrame()\n",
    "    for r, link in zip(page, links): \n",
    "        soup = request_soup(r)\n",
    "        value = get_info_book(soup, link, i)\n",
    "        if value is not None:\n",
    "            df = df.append(value, ignore_index=True)\n",
    "        i = i + 1\n",
    "        print(df.tail())\n",
    "    df.to_csv('./goodread_books.csv')\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    create_csv(11)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}